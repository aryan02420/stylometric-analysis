{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Build a Text Classifier\n",
    "### (NVIDIA NeMo v1.0)\n",
    "\n",
    "<img style=\"float: right;\" src=\"images/nemo/nemo-app-stack.png\" width=400>\n",
    "\n",
    "In this notebook, you'll build an application to classify medical disease abstracts into one of three categories: cancer diseases, neurological diseases and disorders, and \"other\" for anything else.\n",
    "You'll use [NVIDIA NeMo](https://developer.nvidia.com/nvidia-nemo) (Neural Modules) to quickly set up the problem from the command line. \n",
    "\n",
    "**[2.1 NeMo Overview](#2.1-NeMo-Overview)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.1.1 NeMo Models](#2.1.1-NeMo-Models)<br>\n",
    "**[2.2 Text Classification from the Command Line](#2.2-Text-Classification-from-the-Command-Line)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.1 Prepare the Data](#2.2.1-Prepare-the-Data)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.2 Configuration File](#2.2.2-Configuration-File)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.2.2.1 OmegaConf Tool](#2.2.2.1-OmegaConf-Tool)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.3 Hydra-Enabled Python Script](#2.2.3-Hydra-Enabled-Python-Script)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.4 Exercise: Run an Experiment](#2.2.4-Exercise:-Run-an-Experiment)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.5 Visualize the Results with TensorBoard](#2.2.5-Visualize-the-Results-with-TensorBoard)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.6 Exercise: Change the Language Model (Optional!)](#2.2.6-Exercise:-Change-the-Language-Model-(Optional!))<br>\n",
    "**[2.3 PyTorch Lightning Model and Trainer Workflow](#2.3-PyTorch-Lightning-Model-and-Trainer-Workflow)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.1 Script Key Features](#2.3.1-Script-Key-Features)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.2 Model Training from Scratch](#2.3.2-Model-Training-from-Scratch)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.3 Exercise: Query the Model](#2.3.3-Exercise:-Query-the-Model)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.1 NeMo Overview\n",
    "NeMo is an open source toolkit for building conversational AI applications. NeMo is built around [Neural Modules](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html#neural-modules), conceptual blocks of neural networks that take typed inputs and produce typed outputs. Such modules typically represent data layers, encoders, decoders, language models, loss functions, or methods of combining activations. NeMo makes it easy to combine and re-use these building blocks while providing a level of semantic correctness checking via its neural type system.\n",
    "\n",
    "The NeMo deep learning framework is based on [Pytorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning), a PyTorch wrapper that organizes PyTorch code for neural network training.  PyTorch Lightning provides easy and high-performant multi-GPU/multi-node mixed precision training options. Creating a deep neural network project, or **experiment**, with PyTorch Lightning requires two main components:\n",
    "1. [LightningModule](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html)\n",
    "2. [Trainer](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html)\n",
    "\n",
    "The _LightningModule_ is used to organize PyTorch code into computation, optimizers, and loops for training, validation, and test.  This abstraction makes deep learning experiments easier to understand and reproduce. \n",
    "\n",
    "The _Trainer_ is then able to take the LightningModule and automate everything needed for deep learning training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 NeMo Models\n",
    "\n",
    "[NeMo models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html) are LightningModules that come equipped with all supporting infrastructure for training and reproducibility. This includes the deep learning model architecture, data preprocessing, optimizer, checkpoints, and experiment logging. NeMo models, like LightningModules, are also PyTorch modules and are fully compatible with the broader PyTorch ecosystem. Any NeMo model can be taken and plugged into any PyTorch workflow.  \n",
    "\n",
    "**Every NeMo model has an example configuration file and training script that can be found in the [NVIDIA NeMo GitHub Repo](https://github.com/NVIDIA/NeMo/tree/main/examples).**\n",
    "\n",
    "For this class, we'll use a local repo copy included in this environment, based on the downloadable [NGC NeMo container](https://ngc.nvidia.com/catalog/containers/nvidia:nemo), and focus on NLP models.  Execute the following cell to see a tree of NeMo models in the `examples/nlp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree nemo/examples/nlp -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of models listed covering several classic NLP tasks.  We will focus on [text classification](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html) in this notebook and [token classification](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/token_classification.html) in the next notebook on named entity recognition (NER). \n",
    "\n",
    "Notice that each NeMo model type includes a `conf` folder for configuration files and at least one Python training script file.  \n",
    "\n",
    "Execute the following cell to see more detail for the text classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "!tree $TC_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file, `text_classification_config.yaml`, specifies model, training, and experiment management details, such as file locations, pretrained models, and hyperparameters.\n",
    "\n",
    "The Python script, `text_classification_with_bert.py`, encapsulates everything you need to run a text classification experiment defined by the configuration file.  It employs Facebook's [Hydra](https://hydra.cc/) tool for configuration management, which allows you to run the entire experiment just with the script, using command line options to override the config values!\n",
    "\n",
    "The key to building an experiment quickly, is to  understand what the default config file includes, and what needs to be changed for your own project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.2 Text Classification from the Command Line\n",
    "The question we want to answer is: \n",
    "\n",
    "**Given a medical disease abstract, is the abstract about cancer, a neurological disorder, or something else?**\n",
    "\n",
    "This is a 3-class text classification problem.  We'll use the NeMo [text classification model](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html) with three classes (labels): \"cancer\" (0), \"neurological disorders\" (1), and \"other\" (2).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 Prepare the Data\n",
    "You've already explored the [NCBI-disease corpus](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/) and the text classification dataset derived from it in the [Explore the Data](010_ExploreData.ipynb) notebook.  Recall that the text classification files consist of tab-delimited abstracts and labels, with a row of headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC3_DATA_DIR = '/dli/task/data/NCBI_tc-3'\n",
    "!ls $TC3_DATA_DIR/*.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the tab separated data\n",
    "print(\"*****\\ntrain.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/train.tsv\n",
    "print(\"\\n\\n*****\\ndev.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/dev.tsv\n",
    "print(\"\\n\\n*****\\ntest.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note a few features of the data:\n",
    "* The preprocessed data is already in the \n",
    "\n",
    "   ```\n",
    "   [WORD][SPACE][WORD][SPACE][WORD][TAB][LABEL]\n",
    "   ``` \n",
    "   format specified in the [documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html).\n",
    "* There is a header row, \"sentence label\", that should be removed.\n",
    "* The text is quite long, so `max_seq_length` values will need to take this into account for training.\n",
    "\n",
    "Start by removing the header rows.  There are a number of ways to do this, but since it is a simple change we can use a bash stream editor (`sed`) command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 1d $TC3_DATA_DIR/train.tsv > $TC3_DATA_DIR/train_nemo_format.tsv\n",
    "!sed 1d $TC3_DATA_DIR/dev.tsv > $TC3_DATA_DIR/dev_nemo_format.tsv\n",
    "!sed 1d $TC3_DATA_DIR/test.tsv > $TC3_DATA_DIR/test_nemo_format.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the tab separated data\n",
    "# \"1\" is \"positive\" and \"0\" is \"negative\"\n",
    "print(\"*****\\ntrain_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/train_nemo_format.tsv\n",
    "print(\"\\n\\n*****\\ndev_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/dev_nemo_format.tsv\n",
    "print(\"\\n\\n*****\\ntest_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/test_nemo_format.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC3_DATA_DIR = '/dli/task/data/NCBI_tc-3'\n",
    "!ls $TC3_DATA_DIR/*.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Configuration File\n",
    "List the config file `text_classification_config.yaml` and take a look at the keys and default values.  Note the hierarchy of the keys and, especially, the three top-level keys: `trainer`, `model`, and `exp_manager`.\n",
    "\n",
    "```yaml\n",
    "trainer:\n",
    "  gpus:\n",
    "  num_nodes:\n",
    "  max_epochs:\n",
    "  ...\n",
    "  \n",
    "model:\n",
    "  nemo_path:\n",
    "  tokenizer:  \n",
    "  language_model:\n",
    "  classifier_head:\n",
    "  ...\n",
    "\n",
    "exp_manager:\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG_DIR = \"/dli/task/nemo/examples/nlp/text_classification/conf\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "!cat $CONFIG_DIR/$CONFIG_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2.1 OmegaConf Tool\n",
    "The YAML config file provides default values for most of the parameters, but there are a few items that must be specified for the text classification experiment in order to run it at all.  \n",
    "\n",
    "Each YAML section is a bit easier to view using the [omegaconf](https://omegaconf.readthedocs.io/en/2.1_branch/#) package, which allows you to access and manipulate the configuration keys using a \"dot\" protocol.  \n",
    "\n",
    "Start by instantiating an `OmegaConf` object from the config file. Keys in the object can be changed, added, viewed, saved, and so on.  \n",
    "\n",
    "For example, to look at just the `model` section, we can load the config file and specify just the `config.model` section to view through a print statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(CONFIG_DIR + \"/\" + CONFIG_FILE)\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about the model arguments can be found in the [documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html#model-arguments).  The `dataset.num_classes` value as well as locations of the data in `train_ds.file_path`, `val_ds.file_path`, and `test_ds.file_path` are required.\n",
    "\n",
    "To make sure we don't run out of memory, we can limit the `dataset.max_seq_length` to 128.  It also looks like the `infer_samples` are related to movie reviews, so we can change those to sentences that are meaningful in the disease domain.\n",
    "\n",
    "There are some other parameters we might want to change later, but for now, this is all we absolutely must provide.  \n",
    "\n",
    "Next take a look at the `trainer` subsection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(config.trainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have one GPU right now, so that setting is fine, but we might want to limit the `max_epochs` to just a few to start with.  As with the `model` configs, there are some other parameters we might want to change, but we can go with the default for our first try.  \n",
    "\n",
    "Finally, what about the `exp_manager`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(config.exp_manager))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is fine as it is. When the `exp_dir` is `null`, it will default to placing the experiment results in a new directory named `nemo_experiments`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 Hydra-Enabled Python Script\n",
    "To recap, the parameters we need to change or override are:\n",
    "\n",
    "* `model.dataset.num_classes`: set to 3\n",
    "* `model.dataset.max_seq_length`: set to 128\n",
    "* `model.train_ds.file_path`: set to train_nemo_format.tsv\n",
    "* `model.val_ds.file_path`: set to dev_nemo_format.tsv\n",
    "* `model.test_ds.file_path`: set to test_nemo_format.tsv\n",
    "* `model.infer_samples` : set to relevent sentences\n",
    "* `trainer.max_epochs`: set to 3\n",
    "\n",
    "We can train, infer, and test it all **in one command** using the text classification training script!  \n",
    "\n",
    "The script uses Hydra to manage the config file, so that means we can just override the values we want to from the command line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The training takes about 2 minutes to run\n",
    "\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "# set the values we want to override\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES_0 = \"In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia \"\n",
    "INFER_SAMPLES_1 = \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\"\n",
    "INFER_SAMPLES_2 = \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "MAX_EPOCHS = 3\n",
    "\n",
    "# Run the training script, overriding the config values in the command line\n",
    "!python $TC_DIR/text_classification_with_bert.py \\\n",
    "        model.dataset.num_classes=$NUM_CLASSES \\\n",
    "        model.dataset.max_seq_length=$MAX_SEQ_LENGTH \\\n",
    "        model.train_ds.file_path=$PATH_TO_TRAIN_FILE \\\n",
    "        model.validation_ds.file_path=$PATH_TO_VAL_FILE \\\n",
    "        model.test_ds.file_path=$PATH_TO_TEST_FILE \\\n",
    "        model.infer_samples=[\"$INFER_SAMPLES_0\",\"$INFER_SAMPLES_1\",\"$INFER_SAMPLES_2\"] \\\n",
    "        trainer.max_epochs=$MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of each training experiment, there is a printed log of the experiment specification including any parameters added or overridden via the command-line. It also shows additional information, such as which GPUs are available, where logs are saved, and some samples from the datasets with their corresponding inputs to the model. The log also provides some stats on the lengths of sequences in the dataset.\n",
    "\n",
    "After each epoch, there is a summary table of metrics on the validation set which includes precision, recall, and f1 score. The f1 score takes both false positives and false negatives into account and is considered more useful than simple accuracy. \n",
    "\n",
    "At the end of training, NeMo saves the last checkpoint at the path specified by `model.nemo_file_path`.  Since we left this value at the default, it should have been written to our workspace in `.nemo` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results you achieved in the experiment may not have been very good.  However, it is pretty easy to try another experiment with just a few changes.  Longer training, adjusted learning rate, and changing the batch size for the training and validation datasets can improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 Exercise: Run an Experiment\n",
    "Try running another similar experiment using the same text classification problem, this time with some suggested improvements:\n",
    "  \n",
    "* Set the mixed-precision `amp_level` to \"O1\" with a `precision` of 16 to make the model run faster with little or no reduction in accuracy.\n",
    "* Adjust the number of epochs upward a bit to improve results (larger `max_epochs`)\n",
    "* Increase the learning rate a little to allow more rapid response to the estimated error each time the model weights are updated\n",
    "\n",
    "The new values have been provided for you in the cell below.  Add the command with appropriate overrides and run the cell.  If you get stuck, refer to the [solution](solutions/ex2.2.4.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The training takes about 2 minutes to run\n",
    "\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "# set the values we want to override\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES_0 = \"In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia \"\n",
    "INFER_SAMPLES_1 = \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\"\n",
    "INFER_SAMPLES_2 = \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "MAX_EPOCHS = 5\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16\n",
    "LR = 5.0e-05\n",
    "\n",
    "# Override the config values in the command line\n",
    "# FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the result from this experiment compare to the previous one?  Check the F1 scores and inference results in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5 Visualize the Results with TensorBoard\n",
    "The [experiment manager](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html?highlight=tensorboard#experiment-manager) saves results for viewing with TensorBoard. Execute the following cell to create a link to TensorBoard for your instance, then click on the link to open Tensorboard in a tab on your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To compare the performance of the models you've run, select the \"train loss\" scaler.  You can see all the models you've run compared together or select individual models for comparison.  The example below shows the first experiment in orange and the exercise experiment in blue.  You can see that the loss was smaller in the second experiment.\n",
    "\n",
    "<img src=\"images/tensorboard_01.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.6 Exercise: Change the Language Model\n",
    "So far, you've used the basic `bert-base-uncased` language model, but that is just one of many you could try.  Run the following cell to see what language models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# complete list of supported BERT-like models\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "nemo_nlp.modules.get_pretrained_lm_models_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, choose a new language model, such as `megatron-bert-345m-cased`.  \n",
    "\n",
    "You may need to restart the notebook kernal to clear memory.  If you use a large model, other ways to save GPU memory space are to reduce the `batch_size` to 32, 16, or even 8 and reduce the `max_seq_length` to 64. There is no right answer to this exercise.  Rather, this is an opportunity for you to experiment.  Some of the models can take several minutes to run, so feel free to move on to the next notebook and return here when you have time later. If you get stuck, take a look at an example [solution](solutions/ex2.2.6.ipynb).  Be sure to take note of the loss and f1 results with this model, or check TensorBoard for a visualization of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Try your own experiment with a different language model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.3 PyTorch Lightning Model and Trainer Workflow\n",
    "The NeMo model script is the quickest way to get up and running.  Sometimes, though, you may want to create your own script or work through your project in a more customized manner.  In that case, you can step through the PyTorch Lightning workflow, which is otherwise abstracted (encapsulated and hidden) within the model training script. We'll take a look at the script, then try working through the same workflow from scratch without the script or Hydra.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 Script Key Features\n",
    "You can open the [text_classification_with_bert.py](nemo/examples/nlp/text_classification/text_classification_with_bert.py) script to see exactly what is happening.  \n",
    "\n",
    "Here's an abbreviated version with logging and initial comments removed:\n",
    "\n",
    "```python\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from nemo.collections.nlp.models.text_classification import TextClassificationModel\n",
    "from nemo.collections.nlp.parts.nlp_overrides import NLPDDPPlugin\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "\n",
    "@hydra_runner(config_path=\"conf\", config_name=\"text_classification_config\")\n",
    "def main(cfg: DictConfig) -> None:\n",
    "    trainer = pl.Trainer(plugins=[NLPDDPPlugin()], **cfg.trainer)\n",
    "    exp_manager(trainer, cfg.get(\"exp_manager\", None))\n",
    "\n",
    "    if not cfg.model.train_ds.file_path:\n",
    "        raise ValueError(\"'train_ds.file_path' need to be set for the training!\")\n",
    "\n",
    "    model = TextClassificationModel(cfg.model, trainer=trainer)\n",
    "    trainer.fit(model)\n",
    "\n",
    "    if cfg.model.nemo_path:\n",
    "        # '.nemo' file contains the last checkpoint and the params to initialize the model\n",
    "        model.save_to(cfg.model.nemo_path)\n",
    "\n",
    "    # We evaluate the trained model on the test set if test_ds is set in the config file\n",
    "    if cfg.model.test_ds.file_path:\n",
    "        trainer.test(model=model, ckpt_path=None, verbose=False)\n",
    "\n",
    "    # perform inference on a list of queries.\n",
    "    if \"infer_samples\" in cfg.model and cfg.model.infer_samples:       \n",
    "        # max_seq_length=512 is the maximum length BERT supports.\n",
    "        results = model.classifytext(queries=cfg.model.infer_samples, batch_size=16, max_seq_length=512)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "The Hydra decorator, `@hydra_runner`, connects the configuration file and provides the mechanism for the command line overrides. \n",
    "\n",
    "Once the configuration is established, the key steps are:\n",
    "1. Instantiate the trainer with `trainer = pl.Trainer(plugins=[NLPDDPPlugin()], **cfg.trainer)`\n",
    "1. Instantiate the model with `model = TextClassificationModel(cfg.model, trainer=trainer)`\n",
    "1. Train the model with `trainer.fit(model)`\n",
    "\n",
    "Additional steps for optional inference and evaluation are:\n",
    "* Evaluate with `trainer.test(model=model, ckpt_path=None, verbose=False)`\n",
    "* Infer with `results = model.classifytext(queries=cfg.model.infer_samples, batch_size=16, max_seq_length=512)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3.2 Model Training from Scratch\n",
    "Execute the following cell to restart the notebook kernel to clear variables and GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the `nemo_nlp` collection, the experiment manager, PyTorch Lightning, and OmegaConf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections import nlp as nemo_nlp\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running these training steps manually without the script or Hydra, the correct configuration must be set prior to instantiation.  We've already determined the changes we want to make to the config file for this project.  Previously, we used the Hydra override feature in the command line, but those changes are made this time using `OmegaConf`. The syntax looks similar, except this time we are directly changing the `OmegaConf` object, `config`, in Python, and will pass that object to `trainer`, `exp_manager`, and `model`.\n",
    "\n",
    "The default language model is `bert-base-uncased`.  To override it, add to the cell (for example):\n",
    "```python\n",
    "    PRETRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "    config.model.language_model.pretrained_model_name=PRETRAINED_MODEL_NAME\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OmegaConf object by loading the config file\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "config = OmegaConf.load(TC_DIR + \"/conf/\" + CONFIG_FILE)\n",
    "\n",
    "# set the values we want to change\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES = [\"Germline mutations in BRCA1 are responsible for most cases of inherited breast and ovarian cancer \",\n",
    "        \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\",\n",
    "        \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "        ]\n",
    "MAX_EPOCHS = 5\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16\n",
    "LR = 5.0e-05\n",
    "\n",
    "# set the config values using omegaconf\n",
    "config.model.dataset.num_classes = NUM_CLASSES\n",
    "config.model.dataset.max_seq_length = MAX_SEQ_LENGTH\n",
    "config.model.train_ds.file_path = PATH_TO_TRAIN_FILE\n",
    "config.model.validation_ds.file_path = PATH_TO_VAL_FILE\n",
    "config.model.test_ds.file_path = PATH_TO_TEST_FILE\n",
    "config.model.infer_samples = INFER_SAMPLES\n",
    "config.trainer.max_epochs = MAX_EPOCHS\n",
    "config.trainer.amp_level = AMP_LEVEL\n",
    "config.trainer.precision = PRECISION\n",
    "config.model.optim.lr = LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `config` has been updated with the correct values, instantiate the trainer and experiment manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the trainer and experiment manager\n",
    "trainer = pl.Trainer(**config.trainer)\n",
    "exp_manager(trainer, config.exp_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the model \n",
    "model = nemo_nlp.models.TextClassificationModel(config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# start model training and save result\n",
    "# The training takes about 2 minutes to run\n",
    "trainer.fit(model)\n",
    "model.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with `trainer.test`, which will automatically use the file path to the test set we updated in `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run inference using the inference samples from `config`. We can check on them by just printing directly from the `config.model.infer_samples` key object.  It displays as a list of strings.\n",
    "\n",
    "To run inference tor text classification, use the `model.classifytext` method.  The inferred labels are output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(config.model.infer_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifytext(queries=config.model.infer_samples, batch_size=64, max_seq_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3 Exercise: Query the Model\n",
    "What if we wanted to specify additional queries for inference?  The `model.classifytext` method we just used specifies the queries, but they do not _have_ to be in the config file.  We can simply create a list of strings for our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_queries = [\n",
    "    'Clustering of missense mutations in the ataxia-telangiectasia gene in a sporadic T-cell leukaemia',\n",
    "    'Myotonic dystrophy protein kinase is involved in the modulation of the Ca2+ homeostasis in skeletal muscle cells.',\n",
    "    'Constitutional RB1-gene mutations in patients with isolated unilateral retinoblastoma.',\n",
    "    'Hereditary deficiency of the fifth component of complement in man. I. Clinical, immunochemical, and family studies.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the `my_queries` list.  If you get stuck, refer to the [solution](solutions/ex2.3.3.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Run inference over the my_queries list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've built a text classifier with three classes and learned:\n",
    "* How to use NeMo NLP model config files and scripts to quickly create experiments\n",
    "* How to override the config `model`, `trainer`, and `exp_manager settings`\n",
    "* How to train, evaluate, and infer a text classifier using a single command line\n",
    "* How to train, evaluate, and infer a text classifier using PyTorch Lightning\n",
    "\n",
    "You're ready to try a different NLP task.<br>\n",
    "\n",
    "Move on to [3.0 Build a Named Entity Recognizer](030_NamedEntityRecognition.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
