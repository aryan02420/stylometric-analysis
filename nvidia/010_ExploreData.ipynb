{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Explore the Data\n",
    "\n",
    "In this notebook, you'll explore the datasets and annotations for the projects in this section of the course.  The purpose of taking a close look at the data is to provide a clear picture of the inputs for the models, as well as provide insight into how you might structure your own datasets for future projects.\n",
    "\n",
    "**[1.1 Corpus Annotated Data](#1.1-Corpus-Annotated-Data)<br>**\n",
    "**[1.2 Text Classification Dataset](#1.2-Text-Classification-Dataset)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.2.1 Exercise: Explore the Test Set](#1.2.1-Exercise:-Explore-the-Test-Set)<br>\n",
    "**[1.3 NER Dataset](#1.3-NER-Dataset)<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.1 Corpus Annotated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [NCBI-disease corpus](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/) is a set of 793 PubMed abstracts, annotated by 14 annotators. The annotations take the form of HTML-style tags inserted into the abstract text using the clearly defined rules.  The annotations identify named diseases, and can be used to fine-tune a language model to identify disease mentions in future abstracts, *whether those diseases were part of the original training set or not*.  \n",
    "\n",
    "Here's an example of what an annotated abstract from the corpus looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "10021369\tIdentification of APC2, a homologue of the <category=\"Modifier\">adenomatous polyposis coli tumour</category> suppressor .\tThe <category=\"Modifier\">adenomatous polyposis coli ( APC ) tumour</category>-suppressor protein controls the Wnt signalling pathway by forming a complex with glycogen synthase kinase 3beta ( GSK-3beta ) , axin / conductin and betacatenin . Complex formation induces the rapid degradation of betacatenin . In <category=\"Modifier\">colon carcinoma</category> cells , loss of APC leads to the accumulation of betacatenin in the nucleus , where it binds to and activates the Tcf-4 transcription factor ( reviewed in [ 1 ] [ 2 ] ) . Here , we report the identification and genomic structure of APC homologues . Mammalian APC2 , which closely resembles APC in overall domain structure , was functionally analyzed and shown to contain two SAMP domains , both of which are required for binding to conductin . Like APC , APC2 regulates the formation of active betacatenin-Tcf complexes , as demonstrated using transient transcriptional activation assays in APC - / - <category=\"Modifier\">colon carcinoma</category> cells . Human APC2 maps to chromosome 19p13 . 3 . APC and APC2 may therefore have comparable functions in development and <category=\"SpecificDisease\">cancer</category> .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we see the following tags within the abstract:\n",
    "```html\n",
    "<category=\"Modifier\">adenomatous polyposis coli tumour</category>\n",
    "<category=\"Modifier\">adenomatous polyposis coli ( APC ) tumour</category>\n",
    "<category=\"Modifier\">colon carcinoma</category>\n",
    "<category=\"Modifier\">colon carcinoma</category>\n",
    "<category=\"SpecificDisease\">cancer</category>\n",
    "```\n",
    "For our purposes, we will consider any identified category (such as \"Modifier\", \"Specific Disease\", and a few others) to generally be a \"disease\".  If you want to see more examples, you can explore the text of the corpus using the file browser to the left, or open files directly: \n",
    "\n",
    "* [data/NCBI_corpus/NCBI_corpus_training.txt](data/NCBI_corpus/NCBI_corpus_training.txt)\n",
    "* [data/NCBI_corpus/NCBI_corpus_testing.txt](data/NCBI_corpus/NCBI_corpus_testing.txt)\n",
    "* [data/NCBI_corpus/NCBI_corpus_development.txt](data/NCBI_corpus/NCBI_corpus_development.txt)\n",
    "\n",
    "We have two datasets derived from this corpus:  a text classification dataset and a named entity recognition (NER) dataset.  The text classification dataset labels the abstracts among three broad disease groupings.  We'll use this simple split to demonstrate the NLP text classification task.   The NER dataset labels individual words as diseases.  This dataset will be used for the NLP NER task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.2 Text Classification Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text classification task seeks to categorize text according to its content.  Examples of applications for text classification include sentiment analysis (two classes) and topic labeling (multiple classes).  To understand what kind of dataset we need, we first need to decide what question we want to ask.\n",
    "\n",
    "### Sentiment Analysis\n",
    "For example, if we are analyzing the reviews from movies, our question might be:<br>\n",
    "**Given a movie-review sentence, is the sentiment positive or negative?**<br>\n",
    "In such an analysis, we need to look at sentences, and we only have two classes: \"positive\" and \"negative\".  Each sentence in the training set must be labeled as one or the other. Sentiment analysis is widely used by businesses to identify customer sentiment toward products, brands, or services in online conversations and feedback. \n",
    "\n",
    "### Multi-Class Analysis\n",
    "For our multi-class text classification project, we'll ask a different question:<br>\n",
    "**Given a medical disease abstract, is the abstract about cancer, a neurological disorder, or something else?**<br>\n",
    "For our use case, we are looking at entire abstracts, not just sentences, and we have identified three classes: \"cancer\", \"neurological\", and \"other\".  As a naive approach for the purposes of this lab, the abstracts are labeled based on the diseases identified that fall into these three categories.  The data is stored in `.tsv` format.  This is similar to the common `.csv` comma-delimited format, but uses tabs to delimit columns instead.  Execute the following cell to see a list of `.tsv` files for the 3-class datasets for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC_DATA_DIR = '/dli/task/data/NCBI_tc-3/'\n",
    "!ls -lh $TC_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In JupyterLab, you can explore the files and data using the file explorer at the left.  For the notebooks, we'll use [_pandas_](https://pandas.pydata.org/docs/user_guide/index.html) to import and and view the data.  \n",
    "\n",
    "We can import the data into a _pandas_ DataFrame object using the `pd.read_csv()` function, specifying the tab as a delimiter.  The `.head()` function displays the top 5 rows of data.  Each row includes a raw lowercase abstract and a label.  The labels for the three categories of \"cancer\", \"neurological\", and \"other\" are the values 0, 1, and 2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TC_DATA_DIR + 'train.tsv', sep='\\t')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 Exercise: Explore the Test Set\n",
    "Try the same thing for the test set in the next cell. If you get stuck, you can look at the [solution](solutions/ex1.2.1.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the FIXME lines to view the test set.\n",
    "# ???_df = None #FIXME\n",
    "# ???_df.head() #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see very similar examples.  The test samples are  used in our final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.3 NER Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the NER task, we'll ask a new question:<br>\n",
    "**Given sentences from medical abstracts, what diseases are mentioned?**<br>\n",
    "In this case, our data input is sentences from the abstracts, and our labels are the precise locations of the named disease entities.  Take a look at the information provided for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_DATA_DIR = '/dli/task/data/NCBI_ner-3/'\n",
    "!ls -lh $NER_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NER task requires two files: the text sentences, and the labels.  Run the next two cells to see a sample of the two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head $NER_DATA_DIR/text_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head $NER_DATA_DIR/labels_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOB Tagging\n",
    "We can see that the abstract has been broken into sentences.  Each sentence is then further parsed into words with labels that correspond to the original HTML-style tags in the corpus. \n",
    "\n",
    "The sentences and labels in the NER dataset map to each other with _inside, outside, beginning (IOB)_ tagging. Anything separated by white space is a word, including punctuation.  For the first sentence we have the following mapping:\n",
    "\n",
    "```text\n",
    "Identification of APC2 , a homologue of the adenomatous polyposis coli tumour suppressor .\n",
    "O              O  O    O O O         O  O   B           I         I    I      O          O  \n",
    "```\n",
    "\n",
    "Recall the original corpus tags:\n",
    "```html\n",
    "Identification of APC2, a homologue of the <category=\"Modifier\">adenomatous polyposis coli tumour</category> suppressor .\n",
    "```\n",
    "The beginning word of the tagged text, \"adenomatous\", is now IOB-tagged with a <span style=\"font-family:verdana;font-size:110%;\">B</span> (beginning) tag, the other parts of the disease, \"polyposis coli tumour\" tagged with <span style=\"font-family:verdana;font-size:110%;\">I</span> (inside) tags, and everything else tagged as <span style=\"font-family:verdana;font-size:110%;\">O</span> (outside)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've explored the datasets for both the text classification and NER tasks and learned:\n",
    "* Text classification training data has labels mapping categories to text content\n",
    "* NER training data maps words to tags, such as I, O, B (inside, outside, beginning) to identify entities\n",
    "\n",
    "Next, we'll take a brief look at some of the NVIDIA NeMo toolkit features and how to use NeMo to set up and run our NLP tasks.<br>\n",
    "\n",
    "Move on to [2.0 Build a Text Classifier](020_TextClassification.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
