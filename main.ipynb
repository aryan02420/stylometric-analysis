{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = ['aurthur_conan_doyle', 'charles_dickens', 'h_g_wells', 'jane_austen', 'jonathan_swift']\n",
    "common_words = ['the','be','to','of','and','a','in','that','have','I','it','for','not','on','with','he','as','you','do','at','this','but','his','by','from','they','we','say','her','she','or','an','will','my','one','all','would','there','their','what','so','up','out','if','about','who','get','which','go','me','when','make','can','like','time','no','just','him','know','take','people','into','year','your','good','some','could','them','see','other','than','then','now','look','only','come','its','over','think','also','back','after','use','two','how','our','work','first','well','way','even','new','want','because','any','these','give','day','most','us']\n",
    "punct = [\".\", \"?\", \"!\", \",\", \";\", \":\", \"-\", \"“\", \"’\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {}\n",
    "for corpus in corpora:\n",
    "  with open(os.path.join(\"corpora\", corpus), 'r') as file:\n",
    "    input_data[corpus] = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyloAnalysis(object):\n",
    "  def __init__(self, corpus: str, raw: str) -> None:\n",
    "    super().__init__()\n",
    "    self.raw = raw.lower()\n",
    "    self.corpus = corpus  \n",
    "\n",
    "  @property\n",
    "  def tokens(self):\n",
    "    return nltk.word_tokenize(self.raw)\n",
    "\n",
    "  @property\n",
    "  def words(self):\n",
    "    return [token for token in self.tokens if token not in punct]\n",
    "\n",
    "  @property\n",
    "  def unique_words(self):\n",
    "    return set(self.words)\n",
    "\n",
    "  @property\n",
    "  def text(self):\n",
    "    return nltk.text.Text(self.tokens)\n",
    "\n",
    "  @property\n",
    "  def word_text(self):\n",
    "    return nltk.text.Text(self.words)\n",
    "\n",
    "  @property\n",
    "  def type_token_ratio(self):\n",
    "    return len(self.unique_words) / len(self.words)\n",
    "\n",
    "  @property\n",
    "  def token_freq(self):\n",
    "    return nltk.probability.FreqDist(self.text)\n",
    "\n",
    "  @property\n",
    "  def word_freq(self):\n",
    "    return nltk.probability.FreqDist(self.word_text)\n",
    "\n",
    "  @property\n",
    "  def av_word_len(self):\n",
    "    return np.mean([len(word) for word in self.words])\n",
    "\n",
    "  def token_per_1000(self, token: str):\n",
    "    return self.token_freq[token.lower()] / len(self.text) * 1000\n",
    "\n",
    "  def word_per_1000(self, word: str):\n",
    "    return self.word_freq[word.lower()] / len(self.word_text) * 1000\n",
    "  \n",
    "  @property\n",
    "  def common_words_per_1000(self):\n",
    "    return [(word, self.word_per_1000(word)) for word in common_words]\n",
    "\n",
    "  @property\n",
    "  def punct_per_1000(self):\n",
    "    return [(word, self.token_per_1000(word)) for word in punct]\n",
    "\n",
    "  @property\n",
    "  def sentences(self):\n",
    "    return nltk.sent_tokenize(self.raw)\n",
    "\n",
    "  @property\n",
    "  def av_words_per_sent(self):\n",
    "    return np.mean([len(nltk.word_tokenize(sent)) for sent in self.sentences])\n",
    "\n",
    "  @property\n",
    "  def tagged_tokens(self):\n",
    "    return nltk.pos_tag(self.tokens)\n",
    "\n",
    "  @property\n",
    "  def tags(self):\n",
    "    return [tag for (token, tag) in self.tagged_tokens if token not in punct]\n",
    "\n",
    "  @property\n",
    "  def tag_freq(self):\n",
    "    return nltk.probability.FreqDist(self.tags)\n",
    "\n",
    "  def tag_per_100(self, tag: str):\n",
    "    return self.tag_freq[tag] / len(self.tags) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_data = {}\n",
    "for corpus in corpora:\n",
    "  analyzed_data[corpus] = StyloAnalysis(corpus, input_data[corpus])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.83921681405324"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzed_data['h_g_wells'].word_per_1000('the')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
